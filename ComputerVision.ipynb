{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNP6F6n5JwLDTj9XyoODMvS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dimolinas/Computer-Vision-Platzi/blob/main/ComputerVision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "a1XnA5pja9JO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = 'dataset_filtrado.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('dataset')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'dataset/dataset_filtrado'\n",
        "content = os.listdir(path)\n",
        "content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzC5FBodbtK3",
        "outputId": "c253602e-9f62-4647-b043-4c8828db85af"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['07ffa35d1f.jpg',\n",
              " 'e22a1fc8c5.jpg',\n",
              " '0c535fcdfa.jpg',\n",
              " '3b2d25d42c.jpg',\n",
              " '6450b21594.jpg',\n",
              " '533dd3ae49.jpg',\n",
              " '93407ba6ac.jpg',\n",
              " '18cf3b73b6.jpg',\n",
              " 'b22ad30e1b.jpg',\n",
              " 'c554e9b7b4.jpg',\n",
              " '0414eb4d03.jpg',\n",
              " '530a817c7a.jpg',\n",
              " '007d086a0d.jpg',\n",
              " '42e14b904b.jpg',\n",
              " 'cbb99fc122.jpg',\n",
              " '2c3ae2799b.jpg',\n",
              " '4848bc97c4.jpg',\n",
              " 'ea8ce9da21.jpg',\n",
              " '8e933395c2.jpg',\n",
              " '2b37a718bc.jpg',\n",
              " '39339a1089.jpg',\n",
              " '37e9f4c722.jpg',\n",
              " 'cf8db02eac.jpg',\n",
              " '95614aebd9.jpg',\n",
              " 'f8a2cc7848.jpg',\n",
              " 'd01c4bbb38.jpg',\n",
              " '38073088aa.jpg',\n",
              " 'e9379064f8.jpg',\n",
              " '1180fcd71f.jpg',\n",
              " '8a98fca468.jpg',\n",
              " 'abdbb7257d.jpg',\n",
              " '744ca71f5a.jpg',\n",
              " 'e79711e10f.jpg',\n",
              " '2c7120c43a.jpg',\n",
              " '2fdd9eb661.jpg',\n",
              " 'bf5b9af373.jpg',\n",
              " '576c712438.jpg',\n",
              " '89c26158c4.jpg',\n",
              " '486107bbf0.jpg',\n",
              " '2efb6c3c82.jpg',\n",
              " 'fc15988c9a.jpg',\n",
              " '34db31dbb7.jpg',\n",
              " '53f2146ec4.jpg',\n",
              " '7490c9ba04.jpg',\n",
              " '636e60da4d.jpg',\n",
              " 'b59018d131.jpg',\n",
              " 'e4927496c4.jpg',\n",
              " '66d55e26e2.jpg',\n",
              " '3ec8255ddd.jpg',\n",
              " 'e02950195f.jpg',\n",
              " 'f74248c57f.jpg',\n",
              " '5cc8e6c42d.jpg',\n",
              " '6f65ac7a0a.jpg',\n",
              " 'c4054a8f2c.jpg',\n",
              " '2feaa7dff6.jpg',\n",
              " 'ea2cb5917b.jpg',\n",
              " '717e612946.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_general = 'datasetFinal'\n",
        "path_train = '{}/train'.format(path_general)\n",
        "path_test = '{}/test'.format(path_general)\n",
        "\n",
        "os.mkdir(path_general)\n",
        "os.mkdir(path_train)\n",
        "os.mkdir(path_test)"
      ],
      "metadata": {
        "id": "ARn5RgercA2F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import shutil\n",
        "\n",
        "train = 0.7\n",
        "for nCount in range(int(len(content) * train)):\n",
        "  random_choice_img = random.choice(content)\n",
        "  random_choice_img_abs = '{}/{}'.format(path, random_choice_img)\n",
        "  target_img = '{}/{}'.format(path_train, random_choice_img)\n",
        "  shutil.copyfile(random_choice_img_abs, target_img)\n",
        "  content.remove(random_choice_img)"
      ],
      "metadata": {
        "id": "_bCHc7Kcb0mv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img in content:\n",
        "  random_choice_img_abs = '{}/{}'.format(path, img)\n",
        "  target_img = '{}/{}'.format(path_test, img)\n",
        "  shutil.copyfile(random_choice_img_abs, target_img)"
      ],
      "metadata": {
        "id": "Sk7RmG4OfG_h"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/datasetFinal.zip /content/datasetFinal"
      ],
      "metadata": {
        "id": "TocNKMKreFyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ab2d36b-110d-4692-af29-729c43f3e8f7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/datasetFinal/ (stored 0%)\n",
            "  adding: content/datasetFinal/train/ (stored 0%)\n",
            "  adding: content/datasetFinal/train/07ffa35d1f.jpg (deflated 1%)\n",
            "  adding: content/datasetFinal/train/e22a1fc8c5.jpg (deflated 0%)\n",
            "  adding: content/datasetFinal/train/533dd3ae49.jpg (deflated 0%)\n",
            "  adding: content/datasetFinal/train/93407ba6ac.jpg (deflated 0%)\n",
            "  adding: content/datasetFinal/train/18cf3b73b6.jpg (deflated 1%)\n",
            "  adding: content/datasetFinal/train/b22ad30e1b.jpg (deflated 0%)\n",
            "  adding: content/datasetFinal/train/c554e9b7b4.jpg (deflated 0%)\n",
            "  adding: content/datasetFinal/train/0414eb4d03.jpg (deflated 3%)\n",
            "  adding: content/datasetFinal/train/530a817c7a.jpg (deflated 0%)\n",
            "  adding: content/datasetFinal/train/007d086a0d.jpg (deflated 5%)\n",
            "  adding: content/datasetFinal/train/cbb99fc122.jpg (deflated 0%)\n",
            "  adding: content/datasetFinal/train/2c3ae2799b.jpg (deflated 0%)\n",
            "  adding: content/datasetFinal/train/8e933395c2.jpg (deflated 0%)\n",
            "  adding: content/datasetFinal/train/39339a1089.jpg (deflated 0%)\n",
            "  adding: content/datasetFinal/train/37e9f4c722.jpg (deflated 5%)\n",
            "  adding: content/datasetFinal/train/95614aebd9.jpg (deflated 3%)\n",
            "  adding: content/datasetFinal/train/f8a2cc7848.jpg (deflated 3%)\n",
            "  adding: content/datasetFinal/train/d01c4bbb38.jpg (deflated 1%)\n",
            "  adding: content/datasetFinal/train/38073088aa.jpg (deflated 3%)\n",
            "  adding: content/datasetFinal/train/1180fcd71f.jpg (deflated 1%)\n",
            "  adding: content/datasetFinal/train/8a98fca468.jpg (deflated 1%)\n",
            "  adding: content/datasetFinal/train/abdbb7257d.jpg (deflated 1%)\n",
            "  adding: content/datasetFinal/train/e79711e10f.jpg (deflated 2%)\n",
            "  adding: content/datasetFinal/train/2c7120c43a.jpg (deflated 1%)\n",
            "  adding: content/datasetFinal/train/2fdd9eb661.jpg (deflated 0%)\n",
            "  adding: content/datasetFinal/train/bf5b9af373.jpg (deflated 3%)\n",
            "  adding: content/datasetFinal/train/576c712438.jpg (deflated 1%)\n",
            "  adding: content/datasetFinal/train/89c26158c4.jpg (deflated 1%)\n",
            "  adding: content/datasetFinal/train/fc15988c9a.jpg (deflated 4%)\n",
            "  adding: content/datasetFinal/train/34db31dbb7.jpg (deflated 4%)\n",
            "  adding: content/datasetFinal/train/53f2146ec4.jpg (deflated 0%)\n",
            "  adding: content/datasetFinal/train/636e60da4d.jpg (deflated 5%)\n",
            "  adding: content/datasetFinal/train/b59018d131.jpg (deflated 4%)\n",
            "  adding: content/datasetFinal/train/e4927496c4.jpg (deflated 4%)\n",
            "  adding: content/datasetFinal/train/e02950195f.jpg (deflated 0%)\n",
            "  adding: content/datasetFinal/train/f74248c57f.jpg (deflated 0%)\n",
            "  adding: content/datasetFinal/train/c4054a8f2c.jpg (deflated 2%)\n",
            "  adding: content/datasetFinal/train/2feaa7dff6.jpg (deflated 3%)\n",
            "  adding: content/datasetFinal/train/ea2cb5917b.jpg (deflated 3%)\n",
            "  adding: content/datasetFinal/test/ (stored 0%)\n",
            "  adding: content/datasetFinal/test/0c535fcdfa.jpg (deflated 0%)\n",
            "  adding: content/datasetFinal/test/3b2d25d42c.jpg (deflated 0%)\n",
            "  adding: content/datasetFinal/test/6450b21594.jpg (deflated 1%)\n",
            "  adding: content/datasetFinal/test/42e14b904b.jpg (deflated 3%)\n",
            "  adding: content/datasetFinal/test/4848bc97c4.jpg (deflated 0%)\n",
            "  adding: content/datasetFinal/test/ea8ce9da21.jpg (deflated 0%)\n",
            "  adding: content/datasetFinal/test/2b37a718bc.jpg (deflated 0%)\n",
            "  adding: content/datasetFinal/test/cf8db02eac.jpg (deflated 1%)\n",
            "  adding: content/datasetFinal/test/e9379064f8.jpg (deflated 0%)\n",
            "  adding: content/datasetFinal/test/744ca71f5a.jpg (deflated 0%)\n",
            "  adding: content/datasetFinal/test/486107bbf0.jpg (deflated 0%)\n",
            "  adding: content/datasetFinal/test/2efb6c3c82.jpg (deflated 5%)\n",
            "  adding: content/datasetFinal/test/7490c9ba04.jpg (deflated 0%)\n",
            "  adding: content/datasetFinal/test/66d55e26e2.jpg (deflated 0%)\n",
            "  adding: content/datasetFinal/test/3ec8255ddd.jpg (deflated 0%)\n",
            "  adding: content/datasetFinal/test/5cc8e6c42d.jpg (deflated 1%)\n",
            "  adding: content/datasetFinal/test/6f65ac7a0a.jpg (deflated 0%)\n",
            "  adding: content/datasetFinal/test/717e612946.jpg (deflated 3%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pickle\n",
        "import zipfile\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "pcjtyEVPeK9b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf_slim"
      ],
      "metadata": {
        "id": "5iq5XqVgDm6Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7e5bf2e-01dd-4bf0-c5c2-907c00520b7a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf_slim in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf_slim) (1.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#change type file for train and test set\n",
        "type_file = 'test'\n",
        "path = '{}.json'.format(type_file)\n",
        "data_file = open(path)\n",
        "data = json.load(data_file)\n",
        "data"
      ],
      "metadata": {
        "id": "40Y4Y7chDpJi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95311643-1251-4434-ed58-b3ed81c2abce"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': '28b12b2c-036b-45a9-8743-cf51e74a7dc7e950b895-c8c7-4710-a0a9-fb8189e2f28e',\n",
              "  'image': '2fdd9eb661.jpg',\n",
              "  'width': '500',\n",
              "  'height': '611',\n",
              "  'classification': [],\n",
              "  'tags': [{'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 185, 'y': 312, 'w': 218, 'h': 266},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': '96f5750c-9309-4aa7-9eb6-437f39d2784f',\n",
              "    'type': 'bounding_box'}]},\n",
              " {'id': '28b12b2c-036b-45a9-8743-cf51e74a7dc752ac254a-74a0-4e8c-92fe-99ec5a48b7cf',\n",
              "  'image': '6f65ac7a0a.jpg',\n",
              "  'width': '681',\n",
              "  'height': '1023',\n",
              "  'classification': [],\n",
              "  'tags': [{'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 174.4991680532446,\n",
              "     'y': 356.93011647254576,\n",
              "     'w': 240.21963394342762,\n",
              "     'h': 443.0465890183028},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': 'b34e3029-04e5-4296-ac71-df12db276e1b',\n",
              "    'type': 'bounding_box'}]},\n",
              " {'id': '28b12b2c-036b-45a9-8743-cf51e74a7dc7f5bad2a9-cd03-4a5f-b432-0200c12a56f0',\n",
              "  'image': '07ffa35d1f.jpg',\n",
              "  'width': '984',\n",
              "  'height': '738',\n",
              "  'classification': [],\n",
              "  'tags': [{'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 362, 'y': 179, 'w': 444, 'h': 376},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'ec8fcb75-923a-4ea4-b409-483fce1d56a6',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 771, 'y': 167, 'w': 23, 'h': 28},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': 'bbfb8037-0689-4425-8128-ff66e0adfb92',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 754, 'y': 166, 'w': 15, 'h': 24},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': 'b809e857-e302-46a8-9350-06b69db325ce',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 737, 'y': 171, 'w': 22, 'h': 22},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': 'c555efe6-5f38-48bf-aa36-d46b1402d1d2',\n",
              "    'type': 'bounding_box'}]},\n",
              " {'id': '28b12b2c-036b-45a9-8743-cf51e74a7dc77d5eb7c4-a260-444d-b57f-407d2fe44eba',\n",
              "  'image': '8a98fca468.jpg',\n",
              "  'width': '512',\n",
              "  'height': '342',\n",
              "  'classification': [],\n",
              "  'tags': [{'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 57, 'y': 112, 'w': 197, 'h': 160},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '80e3575d-b965-40d8-9638-3764684a9d91',\n",
              "    'type': 'bounding_box'}]},\n",
              " {'id': '28b12b2c-036b-45a9-8743-cf51e74a7dc770027973-f21b-451d-983d-5629135fafe1',\n",
              "  'image': '34db31dbb7.jpg',\n",
              "  'width': '600',\n",
              "  'height': '400',\n",
              "  'classification': [],\n",
              "  'tags': [{'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 203, 'y': 230, 'w': 234, 'h': 118},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': '3bd60339-68fe-49d7-beba-97f991877dbb',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 505, 'y': 237, 'w': 96, 'h': 64},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '65fe7a37-7b15-4dea-a1e3-46da7fa0492f',\n",
              "    'type': 'bounding_box'}]},\n",
              " {'id': '28b12b2c-036b-45a9-8743-cf51e74a7dc7a9bd844b-558d-4111-8d24-6d5fc3d73634',\n",
              "  'image': '37e9f4c722.jpg',\n",
              "  'width': '1280',\n",
              "  'height': '720',\n",
              "  'classification': [],\n",
              "  'tags': [{'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 164, 'y': 313, 'w': 42, 'h': 24},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '05966e70-0c59-4404-bacd-191fca116c69',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 252, 'y': 290, 'w': 41, 'h': 48},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '91520017-217e-4f5f-ab04-9764fc4a8576',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 30, 'y': 300, 'w': 36, 'h': 30},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'd752244c-5e77-4009-9405-bcefed3c29a0',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 81, 'y': 308, 'w': 22, 'h': 17},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'a32caebc-bc3a-4846-bfd4-24ebb80bc739',\n",
              "    'type': 'bounding_box'}]},\n",
              " {'id': '28b12b2c-036b-45a9-8743-cf51e74a7dc7c48acf06-66ce-4422-9073-bd56c3323562',\n",
              "  'image': '42e14b904b.jpg',\n",
              "  'width': '290',\n",
              "  'height': '174',\n",
              "  'classification': [],\n",
              "  'tags': [{'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 47, 'y': 56, 'w': 92, 'h': 88},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': '1c007112-ea1e-4d76-9342-b800d20c0417',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 10, 'y': 69, 'w': 60, 'h': 54},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': '7b85d8de-c45a-4bbe-a238-66f9d06f15a8',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 109, 'y': 32, 'w': 45, 'h': 40},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': '705ac028-a7ac-43ce-b480-311068c5ddec',\n",
              "    'type': 'bounding_box'}]},\n",
              " {'id': '28b12b2c-036b-45a9-8743-cf51e74a7dc770220f5e-5fc3-4945-8702-4a968a907408',\n",
              "  'image': '530a817c7a.jpg',\n",
              "  'width': '1000',\n",
              "  'height': '750',\n",
              "  'classification': [],\n",
              "  'tags': [{'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 115, 'y': 423, 'w': 181, 'h': 257},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': 'f69c42a2-4731-48a7-9510-0ba2e4081b23',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 371, 'y': 443, 'w': 171, 'h': 280},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': '8c73bede-35f1-4f83-b038-7477f202c13a',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 565, 'y': 379, 'w': 166, 'h': 267},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': '6dbc1563-a8a9-479c-a2f8-33f256962406',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 673, 'y': 382, 'w': 217, 'h': 197},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': 'e2d0d3be-1bae-4e11-9f42-b8c69c667d5f',\n",
              "    'type': 'bounding_box'}]},\n",
              " {'id': '28b12b2c-036b-45a9-8743-cf51e74a7dc76e57b134-1b04-4c98-9a90-6d679747c763',\n",
              "  'image': '717e612946.jpg',\n",
              "  'width': '259',\n",
              "  'height': '195',\n",
              "  'classification': [],\n",
              "  'tags': [{'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 48, 'y': 73, 'w': 107, 'h': 87},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': '41dffb29-2b7e-4aba-9e6b-605ee5681fd4',\n",
              "    'type': 'bounding_box'}]},\n",
              " {'id': '28b12b2c-036b-45a9-8743-cf51e74a7dc7d839f7ca-9b6c-410d-84de-a950e74c6fa1',\n",
              "  'image': '4848bc97c4.jpg',\n",
              "  'width': '1207',\n",
              "  'height': '707',\n",
              "  'classification': [],\n",
              "  'tags': [{'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 124, 'y': 317, 'w': 273, 'h': 267},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': '0046d4e7-9071-43db-99c1-a3ae0744578e',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 465, 'y': 220, 'w': 261, 'h': 233},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': 'b5f7d5a0-1e9b-4bff-a848-cde067360fb6',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 610, 'y': 463, 'w': 268, 'h': 208},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': '63e4fa2e-ea1c-4a98-a932-7d6a3cfb6667',\n",
              "    'type': 'bounding_box'}]},\n",
              " {'id': '28b12b2c-036b-45a9-8743-cf51e74a7dc7254a041d-7340-406d-b7d7-8d62c0dea8f7',\n",
              "  'image': '486107bbf0.jpg',\n",
              "  'width': '1200',\n",
              "  'height': '900',\n",
              "  'classification': [],\n",
              "  'tags': [{'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 852, 'y': 282, 'w': 289, 'h': 293},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': '55517ef3-e32d-48f4-9889-4f37344e6d8a',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 165, 'y': 335, 'w': 220, 'h': 372},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': 'f43001d5-aae1-4017-bdac-c3d43fbc6a28',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 18, 'y': 253, 'w': 178, 'h': 297},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': '90151fa3-aab2-4c16-a7c7-b4339a9d157b',\n",
              "    'type': 'bounding_box'}]},\n",
              " {'id': '28b12b2c-036b-45a9-8743-cf51e74a7dc708a22ced-6309-4d68-8974-6a10d0172d04',\n",
              "  'image': '38073088aa.jpg',\n",
              "  'width': '640',\n",
              "  'height': '428',\n",
              "  'classification': [],\n",
              "  'tags': [{'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 21, 'y': 399, 'w': 92, 'h': 28},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '6847f52e-4dca-4ef7-a85a-6830c6565046',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 3, 'y': 360, 'w': 69, 'h': 62},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '3e148104-bee9-42cf-966c-57dbf68e078d',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 45, 'y': 336, 'w': 75, 'h': 60},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '88d5c1bf-5cd5-47b5-9c89-e418af17de6f',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 102, 'y': 366, 'w': 107, 'h': 62},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'e693c00a-180c-4cd0-b145-1fc47ea00a51',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 101, 'y': 276, 'w': 89, 'h': 84},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '78be20bb-211f-4918-afb6-b459a673bedc',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 151, 'y': 346, 'w': 63, 'h': 53},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'eb44af5b-917f-4131-8121-a70a6bd27e9b',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 149, 'y': 325, 'w': 68, 'h': 39},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'bdcbf58f-90e2-486b-b397-81efd9e004ee',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 150, 'y': 260, 'w': 97, 'h': 76},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '2cdb2f12-f7be-46e4-8f90-5688803b5dc6',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 181, 'y': 217, 'w': 82, 'h': 89},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'ecb43421-b166-4654-9bad-dbdb98bcca79',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 219, 'y': 406, 'w': 88, 'h': 21},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'a5fda5eb-4328-482f-981d-69babeaf4feb',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 370, 'y': 376, 'w': 92, 'h': 51},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '1343e09b-aa7b-4456-8ee3-9f865f534ade',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 252, 'y': 351, 'w': 82, 'h': 71},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '9fa72c4f-c548-4844-8d74-62f761ace5c1',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 255, 'y': 304, 'w': 77, 'h': 61},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'e418b9dd-5d76-4f80-aea3-810b57253c04',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 288, 'y': 277, 'w': 47, 'h': 39},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '0b8928ba-eca7-4788-8b15-14f8d0d1f953',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 293, 'y': 254, 'w': 45, 'h': 32},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '178ca252-d3d2-477a-82ef-723b7a7f54e1',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 313, 'y': 242, 'w': 34, 'h': 31},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'c48fe0ea-4d12-4624-8195-7dcd31716cf5',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 374, 'y': 348, 'w': 65, 'h': 46},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '62c499ad-e846-4a73-a945-0983e55a2fa1',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 400, 'y': 317, 'w': 55, 'h': 54},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '6d8e87b8-e91d-4136-a6ad-8b9bd54384d3',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 385, 'y': 302, 'w': 53, 'h': 45},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '05d044e8-2768-4c03-80dd-fad0aa5fe823',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 385, 'y': 285, 'w': 45, 'h': 28},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'fb2a30c1-bf2f-43f3-aec1-57d1562c80e1',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 385, 'y': 268, 'w': 38, 'h': 29},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '6f0a79d8-fb91-45ec-b6e6-da144d257a64',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 380, 'y': 250, 'w': 38, 'h': 29},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '5b0ec0aa-663a-4306-be48-8a47d3fbc652',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 371, 'y': 242, 'w': 39, 'h': 37},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '6c5dbf6f-f021-477a-94eb-bb6b02b33f01',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 383, 'y': 232, 'w': 35, 'h': 24},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'ab478008-eaf2-4e61-9db4-241bcee12d2b',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 499, 'y': 336, 'w': 73, 'h': 65},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '283531bd-6682-4755-9d62-f6433a460de7',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 493, 'y': 315, 'w': 54, 'h': 44},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '20abb016-b20b-41a4-9141-1e7ba3dde641',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 488, 'y': 298, 'w': 50, 'h': 42},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '242f963c-85f5-4607-bb72-875439ab21df',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 449, 'y': 214, 'w': 71, 'h': 97},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'e6c1f797-2c3b-4316-b782-10327c54a992',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 468, 'y': 103, 'w': 81, 'h': 97},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '61e40244-97f3-4ec3-8bfe-1b4c3200c009',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 438, 'y': 58, 'w': 34, 'h': 49},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '96479aeb-65e3-471f-b732-25aa7a831a9f',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 416, 'y': 40, 'w': 25, 'h': 35},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '915dd33f-43fb-45f9-8f77-d705e738b153',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 163, 'y': 43, 'w': 137, 'h': 26},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '8872dd57-71de-41b2-862e-dddc0a4dbc14',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 376, 'y': 38, 'w': 115, 'h': 23},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'dad38dc3-ee9c-4367-9998-a8656aa3d803',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 506, 'y': 34, 'w': 61, 'h': 18},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '00dff23b-f6dc-4d25-b965-9d08911f7669',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 290, 'y': 214, 'w': 27, 'h': 36},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '5d21f14b-55ae-434c-81cb-8b56cb5c356c',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 366, 'y': 189, 'w': 48, 'h': 47},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '92d26138-2d56-488c-93b8-d4fa5aec5062',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 442, 'y': 227, 'w': 29, 'h': 30},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'f6d14998-65d2-4dc0-810c-d0b7194076fe',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 434, 'y': 220, 'w': 26, 'h': 33},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '10da2fa8-298a-4983-be58-f2a704d84dae',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 420, 'y': 183, 'w': 31, 'h': 49},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '470af742-a655-4ef7-9d27-5f9e98c90439',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 284, 'y': 187, 'w': 34, 'h': 32},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '56916447-96a6-4ca1-8ed6-1190bbcc254e',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 328, 'y': 210, 'w': 26, 'h': 26},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'fcfe3bfe-6607-44ac-99bb-391564f2897e',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 232, 'y': 314, 'w': 22, 'h': 59},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': '43a159df-e197-409f-b145-b2bcd3898d2f',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 336, 'y': 346, 'w': 30, 'h': 63},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': '9f820625-3c21-4352-81f0-9cf85fd102e1',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 355, 'y': 318, 'w': 29, 'h': 59},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': '4feb7431-f543-4cb8-a8dd-3ae2b0ab293b',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 345, 'y': 302, 'w': 26, 'h': 38},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': '19eae101-9385-483f-a098-648ea1ad4515',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 522, 'y': 218, 'w': 26, 'h': 39},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': '4253c285-e75c-4a03-af18-3fa9ecae5778',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 451, 'y': 305, 'w': 34, 'h': 63},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': '989ef306-e9f0-43a5-ac0f-6328ca18faed',\n",
              "    'type': 'bounding_box'}]},\n",
              " {'id': '28b12b2c-036b-45a9-8743-cf51e74a7dc761610a95-2595-4790-9180-7bdd19e899c3',\n",
              "  'image': 'bf5b9af373.jpg',\n",
              "  'width': '615',\n",
              "  'height': '461',\n",
              "  'classification': [],\n",
              "  'tags': [{'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 161, 'y': 174, 'w': 160, 'h': 259},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': 'd09adabd-d99c-48d4-97b8-79987dc11925',\n",
              "    'type': 'bounding_box'}]},\n",
              " {'id': '28b12b2c-036b-45a9-8743-cf51e74a7dc7ebb34344-f5a9-478c-acf9-effa6aadcdff',\n",
              "  'image': 'cbb99fc122.jpg',\n",
              "  'width': '780',\n",
              "  'height': '440',\n",
              "  'classification': [],\n",
              "  'tags': [{'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 46, 'y': 94, 'w': 280, 'h': 269},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': 'c3eec9fd-20fe-4a99-bccc-fc59363474f4',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 351, 'y': 96, 'w': 423, 'h': 338},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': '18c7b746-16c7-439f-aa81-ac147d07e54e',\n",
              "    'type': 'bounding_box'}]},\n",
              " {'id': '28b12b2c-036b-45a9-8743-cf51e74a7dc717115530-910e-4a0c-bf40-ad4ddcdfd8e7',\n",
              "  'image': 'd01c4bbb38.jpg',\n",
              "  'width': '1000',\n",
              "  'height': '650',\n",
              "  'classification': [],\n",
              "  'tags': [{'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 188, 'y': 488, 'w': 292, 'h': 162},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'db3b7588-39db-433a-b4da-b02e72330ef8',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 587, 'y': 483, 'w': 204, 'h': 163},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'a81130c0-e889-499b-b74b-0b8c09163d8d',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 683, 'y': 440, 'w': 197, 'h': 181},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '290ba70b-8a28-4c5a-a25a-a07fcb5d0130',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 629, 'y': 410, 'w': 162, 'h': 100},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'bb726927-9e28-4184-b3b5-bdde52caa406',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 1, 'y': 244, 'w': 206, 'h': 347},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'ef2412f4-6757-4173-b7a0-d37daac24d22',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 287, 'y': 400, 'w': 164, 'h': 99},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '9c117d10-6028-490b-9bc4-c741e7e6eed2',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 342, 'y': 459, 'w': 177, 'h': 183},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '36e9ec8b-34cd-4400-974e-1e1581fc429a',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 289, 'y': 323, 'w': 148, 'h': 116},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '0e93b988-51f7-4095-b892-24e19e0df368',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 167, 'y': 307, 'w': 102, 'h': 105},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '17ddbed3-8b37-45d7-990d-15276a7a0c42',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 747, 'y': 310, 'w': 248, 'h': 103},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '03a1966a-5e32-419d-b1bf-eb141e274248',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 658, 'y': 298, 'w': 104, 'h': 75},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '8eaf847e-4645-4970-b937-71ffc5070ef9',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 646, 'y': 276, 'w': 97, 'h': 73},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'a898c596-5484-4693-87f4-a36babcd107c',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 486, 'y': 307, 'w': 123, 'h': 100},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '0a82c99e-e8e9-4f09-b9b1-20e9a32eb6d1',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 514, 'y': 326, 'w': 124, 'h': 113},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '4421015d-beea-4aa2-b194-e62d69a44bc2',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 528, 'y': 350, 'w': 144, 'h': 120},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '390b475c-270a-4f99-98da-8f935f81eda6',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 197, 'y': 259, 'w': 101, 'h': 91},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'b867e055-3f1f-47ba-b2a0-0379ce7d7559',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 202, 'y': 224, 'w': 109, 'h': 102},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '6e1dd93e-9e34-4a82-add9-530ce330bcf0',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 237, 'y': 188, 'w': 99, 'h': 111},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'ca2eded6-07c4-4ca4-b4e1-e74028cee8db',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 452, 'y': 224, 'w': 77, 'h': 76},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '6110aa3f-0e8c-4d8c-af3d-a2800a391acc',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 560, 'y': 228, 'w': 100, 'h': 89},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '366de787-63d9-42b6-a54e-0bd788c45d4b',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 348, 'y': 219, 'w': 93, 'h': 80},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'c98d2ef8-2576-4a99-a249-c69760b213d9',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 479, 'y': 195, 'w': 81, 'h': 75},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'f31110de-5513-4fc3-ba04-9173f3ff51fa',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 393, 'y': 199, 'w': 50, 'h': 63},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '69a56109-1725-40e6-8279-2a741071be0d',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 456, 'y': 177, 'w': 51, 'h': 59},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'd7045fd3-f7a2-4723-bf1e-a1f5b3ac3330',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 394, 'y': 173, 'w': 63, 'h': 67},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '442a057e-2a32-4ed3-8774-a67d1970de8d',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 311, 'y': 167, 'w': 61, 'h': 53},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': '851d6e42-77b7-4030-9867-3af5b5d7eaa7',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 915, 'y': 433, 'w': 80, 'h': 188},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': 'ee0c2be5-1c3c-4448-bf75-9ed2139954ed',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 832, 'y': 370, 'w': 56, 'h': 132},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': 'eb353953-db67-4f4e-9543-9b450e9c97c3',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 562, 'y': 361, 'w': 91, 'h': 167},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': '9e50f5ef-e290-438a-abbf-505960dd8c5c',\n",
              "    'type': 'bounding_box'}]},\n",
              " {'id': '28b12b2c-036b-45a9-8743-cf51e74a7dc777712d26-2b31-4120-b14e-b32a95027c25',\n",
              "  'image': 'e22a1fc8c5.jpg',\n",
              "  'width': '1240',\n",
              "  'height': '561',\n",
              "  'classification': [],\n",
              "  'tags': [{'parent': None,\n",
              "    'color': '#5310ea',\n",
              "    'pos': {'x': 328, 'y': 127, 'w': 562, 'h': 326},\n",
              "    'classes': [],\n",
              "    'name': 'carro',\n",
              "    'id': 'bb8f11e5-d9a1-4134-ae1e-a5e489bb9b37',\n",
              "    'type': 'bounding_box'}]},\n",
              " {'id': '28b12b2c-036b-45a9-8743-cf51e74a7dc7e3617ba4-f924-468f-8ed6-17355ffb4c0a',\n",
              "  'image': 'e79711e10f.jpg',\n",
              "  'width': '860',\n",
              "  'height': '782',\n",
              "  'classification': [],\n",
              "  'tags': [{'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 483, 'y': 242, 'w': 223, 'h': 327},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': 'ca2cd6ca-d33a-4701-a2da-97448a37fc80',\n",
              "    'type': 'bounding_box'}]},\n",
              " {'id': '28b12b2c-036b-45a9-8743-cf51e74a7dc709794c09-1da8-46ab-a955-e0501bdd3def',\n",
              "  'image': 'e02950195f.jpg',\n",
              "  'width': '400',\n",
              "  'height': '300',\n",
              "  'classification': [],\n",
              "  'tags': [{'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 102, 'y': 143, 'w': 39, 'h': 88},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': 'ad1dd475-6b86-4061-bc58-bdd43518f456',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 126, 'y': 151, 'w': 35, 'h': 65},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': '3263a5d4-0724-4da9-bba7-5d831052b383',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 148, 'y': 148, 'w': 33, 'h': 61},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': 'cd958704-cc4a-414a-a580-46407d700d1b',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 190, 'y': 139, 'w': 34, 'h': 87},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': '6dbf83c0-7e28-4f90-a09e-ce70ee9253e1',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 238, 'y': 142, 'w': 40, 'h': 75},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': 'b4c46db8-c649-4ef7-b1fe-988e297bbe2e',\n",
              "    'type': 'bounding_box'},\n",
              "   {'parent': None,\n",
              "    'color': '#6d160f',\n",
              "    'pos': {'x': 283, 'y': 141, 'w': 42, 'h': 83},\n",
              "    'classes': [],\n",
              "    'name': 'motos',\n",
              "    'id': '784d6f77-01dc-4b87-963c-35fc5ab51928',\n",
              "    'type': 'bounding_box'}]}]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_list = []\n",
        "for classification in data:\n",
        "  width, height, = classification['width'], classification['height']\n",
        "  image = classification['image']\n",
        "  for item in classification['tags']:\n",
        "    name = item['name']\n",
        "    xmin = item['pos']['x']\n",
        "    ymin = item['pos']['y']\n",
        "    xmax = xmin + item['pos']['w']\n",
        "    ymax = ymin + item['pos']['h']\n",
        "\n",
        "    value = (image, width, height, name, xmin, ymin, xmax, ymax)\n",
        "    csv_list.append(value)\n",
        "column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "csv_df = pd.DataFrame(csv_list, columns=column_name)\n",
        "csv_df.to_csv('{}_labels.csv'.format(type_file))\n",
        "csv_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "9Zp1QD9jD7_e",
        "outputId": "0dc34ba7-3037-4a4f-f06b-c2f4e59c9b81"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           filename width height  class        xmin        ymin        xmax  \\\n",
              "0    2fdd9eb661.jpg   500    611  motos  185.000000  312.000000  403.000000   \n",
              "1    6f65ac7a0a.jpg   681   1023  motos  174.499168  356.930116  414.718802   \n",
              "2    07ffa35d1f.jpg   984    738  carro  362.000000  179.000000  806.000000   \n",
              "3    07ffa35d1f.jpg   984    738  motos  771.000000  167.000000  794.000000   \n",
              "4    07ffa35d1f.jpg   984    738  motos  754.000000  166.000000  769.000000   \n",
              "..              ...   ...    ...    ...         ...         ...         ...   \n",
              "109  e02950195f.jpg   400    300  motos  126.000000  151.000000  161.000000   \n",
              "110  e02950195f.jpg   400    300  motos  148.000000  148.000000  181.000000   \n",
              "111  e02950195f.jpg   400    300  motos  190.000000  139.000000  224.000000   \n",
              "112  e02950195f.jpg   400    300  motos  238.000000  142.000000  278.000000   \n",
              "113  e02950195f.jpg   400    300  motos  283.000000  141.000000  325.000000   \n",
              "\n",
              "           ymax  \n",
              "0    578.000000  \n",
              "1    799.976705  \n",
              "2    555.000000  \n",
              "3    195.000000  \n",
              "4    190.000000  \n",
              "..          ...  \n",
              "109  216.000000  \n",
              "110  209.000000  \n",
              "111  226.000000  \n",
              "112  217.000000  \n",
              "113  224.000000  \n",
              "\n",
              "[114 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-05125ef1-2fa2-4b07-957c-927c6c1bedcd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>class</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2fdd9eb661.jpg</td>\n",
              "      <td>500</td>\n",
              "      <td>611</td>\n",
              "      <td>motos</td>\n",
              "      <td>185.000000</td>\n",
              "      <td>312.000000</td>\n",
              "      <td>403.000000</td>\n",
              "      <td>578.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6f65ac7a0a.jpg</td>\n",
              "      <td>681</td>\n",
              "      <td>1023</td>\n",
              "      <td>motos</td>\n",
              "      <td>174.499168</td>\n",
              "      <td>356.930116</td>\n",
              "      <td>414.718802</td>\n",
              "      <td>799.976705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>07ffa35d1f.jpg</td>\n",
              "      <td>984</td>\n",
              "      <td>738</td>\n",
              "      <td>carro</td>\n",
              "      <td>362.000000</td>\n",
              "      <td>179.000000</td>\n",
              "      <td>806.000000</td>\n",
              "      <td>555.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>07ffa35d1f.jpg</td>\n",
              "      <td>984</td>\n",
              "      <td>738</td>\n",
              "      <td>motos</td>\n",
              "      <td>771.000000</td>\n",
              "      <td>167.000000</td>\n",
              "      <td>794.000000</td>\n",
              "      <td>195.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>07ffa35d1f.jpg</td>\n",
              "      <td>984</td>\n",
              "      <td>738</td>\n",
              "      <td>motos</td>\n",
              "      <td>754.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>769.000000</td>\n",
              "      <td>190.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>e02950195f.jpg</td>\n",
              "      <td>400</td>\n",
              "      <td>300</td>\n",
              "      <td>motos</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>151.000000</td>\n",
              "      <td>161.000000</td>\n",
              "      <td>216.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>e02950195f.jpg</td>\n",
              "      <td>400</td>\n",
              "      <td>300</td>\n",
              "      <td>motos</td>\n",
              "      <td>148.000000</td>\n",
              "      <td>148.000000</td>\n",
              "      <td>181.000000</td>\n",
              "      <td>209.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>e02950195f.jpg</td>\n",
              "      <td>400</td>\n",
              "      <td>300</td>\n",
              "      <td>motos</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>139.000000</td>\n",
              "      <td>224.000000</td>\n",
              "      <td>226.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>e02950195f.jpg</td>\n",
              "      <td>400</td>\n",
              "      <td>300</td>\n",
              "      <td>motos</td>\n",
              "      <td>238.000000</td>\n",
              "      <td>142.000000</td>\n",
              "      <td>278.000000</td>\n",
              "      <td>217.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>e02950195f.jpg</td>\n",
              "      <td>400</td>\n",
              "      <td>300</td>\n",
              "      <td>motos</td>\n",
              "      <td>283.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>325.000000</td>\n",
              "      <td>224.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>114 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05125ef1-2fa2-4b07-957c-927c6c1bedcd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-05125ef1-2fa2-4b07-957c-927c6c1bedcd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-05125ef1-2fa2-4b07-957c-927c6c1bedcd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9a11eb65-93b7-4b49-a254-3c4605464f6e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9a11eb65-93b7-4b49-a254-3c4605464f6e')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9a11eb65-93b7-4b49-a254-3c4605464f6e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "%cd /content/models/\n",
        "!git checkout 58d19c67e1d30d905dd5c6e5092348658fed80af\n",
        "!apt-get update && apt-get install -y -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "!pip install -q pycocotools\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4srQ0fAoEb6k",
        "outputId": "6264991a-716e-4796-b329-9cc35a53307d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/models\n",
            "Note: switching to '58d19c67e1d30d905dd5c6e5092348658fed80af'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at 58d19c67e Internal change\n",
            "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [966 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,257 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [993 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,235 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:15 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,197 kB]\n",
            "Get:16 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,127 kB]\n",
            "Fetched 8,135 kB in 4s (1,836 kB/s)\n",
            "Reading package lists... Done\n",
            "E: Unable to locate package python-pil\n",
            "E: Unable to locate package python-lxml\n",
            "/content/models/research\n",
            "object_detection/protos/input_reader.proto:5:1: warning: Import object_detection/protos/image_resizer.proto is unused.\n",
            "2023-09-17 22:15:21.241941: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-09-17 22:15:22.176526: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "\n",
        "import os\n",
        "import io\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "sys.path.append(\"../../models/research\")\n",
        "\n",
        "from PIL import Image\n",
        "from object_detection.utils import dataset_util\n",
        "from collections import namedtuple, OrderedDict\n",
        "\n",
        "# TO-DO replace this with label map\n",
        "# for multiple labels add more else if statements\n",
        "def class_text_to_int(row_label):\n",
        "  if row_label == 'carro':\n",
        "    return 1\n",
        "  elif row_label == 'motos':\n",
        "    return 2\n",
        "  # comment upper if statement and uncomment these statements for multiple labelling\n",
        "  # if row_label == FLAGS.label0:\n",
        "  #   return 1\n",
        "  # elif row_label == FLAGS.label1:\n",
        "  #   return 0\n",
        "  else:\n",
        "    None\n",
        "\n",
        "\n",
        "def split(df, group):\n",
        "  data = namedtuple('data', ['filename', 'object'])\n",
        "  gb = df.groupby(group)\n",
        "  return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "\n",
        "def create_tf_example(group, path):\n",
        "  with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
        "    encoded_jpg = fid.read()\n",
        "  encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "  image = Image.open(encoded_jpg_io)\n",
        "  width, height = image.size\n",
        "\n",
        "  filename = group.filename.encode('utf8')\n",
        "  image_format = b'jpg'\n",
        "  # check if the image format is matching with your images.\n",
        "  xmins = []\n",
        "  xmaxs = []\n",
        "  ymins = []\n",
        "  ymaxs = []\n",
        "  classes_text = []\n",
        "  classes = []\n",
        "\n",
        "  for index, row in group.object.iterrows():\n",
        "    xmins.append(row['xmin'] / width)\n",
        "    xmaxs.append(row['xmax'] / width)\n",
        "    ymins.append(row['ymin'] / height)\n",
        "    ymaxs.append(row['ymax'] / height)\n",
        "    classes_text.append(row['class'].encode('utf8'))\n",
        "    classes.append(class_text_to_int(row['class']))\n",
        "\n",
        "  tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "    'image/height': dataset_util.int64_feature(height),\n",
        "    'image/width': dataset_util.int64_feature(width),\n",
        "    'image/filename': dataset_util.bytes_feature(filename),\n",
        "    'image/source_id': dataset_util.bytes_feature(filename),\n",
        "    'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "    'image/format': dataset_util.bytes_feature(image_format),\n",
        "    'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "    'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "    'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "    'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "    'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "    'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "  }))\n",
        "  return tf_example\n",
        "\n",
        "type_set = 'train'\n",
        "output_path = '/content/{}.record'.format(type_set)\n",
        "image_dir = '/content/dataset/dataset_filtrado'\n",
        "csv_input = '/content/{}_labels.csv'.format(type_set)\n",
        "path = os.path.join(image_dir)\n",
        "\n",
        "writer = tf.io.TFRecordWriter(output_path)\n",
        "\n",
        "examples = pd.read_csv(csv_input)\n",
        "grouped = split(examples, 'filename')\n",
        "\n",
        "for group in grouped:\n",
        "  tf_example = create_tf_example(group, path)\n",
        "  writer.write(tf_example.SerializeToString())\n",
        "\n",
        "writer.close()\n",
        "output_path = os.path.join(os.getcwd(), output_path)\n",
        "print('Successfully created the TFRecords: {}'.format(output_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-ilXR5CEopu",
        "outputId": "92c5b446-0d9f-4fe0-b2e9-a852d2e0e713"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created the TFRecords: /content/train.record\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "import pickle\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "# Instalamos los paquetes necesarios para que funcione desde la Colab\n",
        "!pip install avro-python3\n",
        "!pip install\n",
        "!pip install tf_slim==1.1.0\n",
        "!pip install tf-models-official==2.7.0\n",
        "!pip install lvis\n",
        "!pip install tensorflow_io==0.23.1\n",
        "!pip install keras==2.7.0\n",
        "!pip install opencv-python-headless==4.5.2.52"
      ],
      "metadata": {
        "id": "Uq33Ny2MIZ71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "362755e7-6538-48f3-b9cb-3da458d80d30"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: avro-python3\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43991 sha256=e8cb5c96d79e58c6082296487046f8ab3b05c76e7e52e204fe1b29f86240be28\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/85/62/6cdd81c56f923946b401cecff38055b94c9b766927f7d8ca82\n",
            "Successfully built avro-python3\n",
            "Installing collected packages: avro-python3\n",
            "Successfully installed avro-python3-1.10.2\n",
            "\u001b[31mERROR: You must give at least one requirement to install (see \"pip help install\")\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: tf_slim==1.1.0 in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf_slim==1.1.0) (1.4.0)\n",
            "Collecting tf-models-official==2.7.0\n",
            "  Downloading tf_models_official-2.7.0-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0) (3.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0) (9.4.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0) (2.84.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0) (1.5.16)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0) (1.23.5)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0) (4.8.0.76)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0) (1.5.3)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0) (9.0.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0) (2.0.7)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0) (6.0.1)\n",
            "Collecting sacrebleu (from tf-models-official==2.7.0)\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0) (1.11.2)\n",
            "Collecting sentencepiece (from tf-models-official==2.7.0)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval (from tf-models-official==2.7.0)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0) (1.16.0)\n",
            "Collecting tensorflow-addons (from tf-models-official==2.7.0)\n",
            "  Downloading tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.1/612.1 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0) (4.9.2)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0) (0.14.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official==2.7.0)\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-text>=2.7.0 (from tf-models-official==2.7.0)\n",
            "  Downloading tensorflow_text-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0) (2.13.0)\n",
            "Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.7.0) (1.1.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.0) (0.22.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.0) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.0) (0.1.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.0) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.0) (4.1.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0) (2.0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0) (6.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.22.0->tf-models-official==2.7.0) (2023.3.post1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (67.7.2)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (0.33.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.7.0) (0.1.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.7.0) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.7.0) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.7.0) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.7.0) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.7.0) (3.1.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.7.0) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.7.0) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.7.0) (4.9)\n",
            "Collecting portalocker (from sacrebleu->tf-models-official==2.7.0)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official==2.7.0) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official==2.7.0) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->tf-models-official==2.7.0)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official==2.7.0) (4.9.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official==2.7.0) (1.2.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->tf-models-official==2.7.0)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0) (8.1.7)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0) (1.4.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0) (0.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.7.0->tf-models-official==2.7.0) (0.41.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official==2.7.0) (6.0.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official==2.7.0) (3.16.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.7.0) (1.60.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0) (5.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle>=1.3.9->tf-models-official==2.7.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle>=1.3.9->tf-models-official==2.7.0) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.7.0) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.7.0) (3.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.7.0->tf-models-official==2.7.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.7.0->tf-models-official==2.7.0) (3.4.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.7.0->tf-models-official==2.7.0) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.7.0->tf-models-official==2.7.0) (2.3.7)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official==2.7.0) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.7.0) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=2.7.0->tf-models-official==2.7.0) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow>=2.7.0->tf-models-official==2.7.0) (2.1.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=2.7.0->tf-models-official==2.7.0) (3.2.2)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=dc5b8dee847a87fbbcf74940bf0eb41b62414c9c576c51fd04bd48501f587eaa\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: sentencepiece, typeguard, tensorflow-model-optimization, portalocker, colorama, tensorflow-addons, sacrebleu, seqeval, tensorflow-text, tf-models-official\n",
            "Successfully installed colorama-0.4.6 portalocker-2.8.2 sacrebleu-2.3.1 sentencepiece-0.1.99 seqeval-1.2.2 tensorflow-addons-0.21.0 tensorflow-model-optimization-0.7.5 tensorflow-text-2.13.0 tf-models-official-2.7.0 typeguard-2.13.3\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lvis) (0.11.0)\n",
            "Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.10/dist-packages (from lvis) (3.0.2)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lvis) (1.4.5)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.10/dist-packages (from lvis) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from lvis) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis) (4.8.0.76)\n",
            "Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from lvis) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from lvis) (2.8.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from lvis) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->lvis) (1.1.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->lvis) (4.42.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->lvis) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->lvis) (9.4.0)\n",
            "Installing collected packages: lvis\n",
            "Successfully installed lvis-0.5.3\n",
            "Collecting tensorflow_io==0.23.1\n",
            "  Downloading tensorflow_io-0.23.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-io-gcs-filesystem==0.23.1 (from tensorflow_io==0.23.1)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.23.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow-io-gcs-filesystem, tensorflow_io\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.33.0\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.33.0:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.33.0\n",
            "Successfully installed tensorflow-io-gcs-filesystem-0.23.1 tensorflow_io-0.23.1\n",
            "Collecting keras==2.7.0\n",
            "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.13.1\n",
            "    Uninstalling keras-2.13.1:\n",
            "      Successfully uninstalled keras-2.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.13.0 requires keras<2.14,>=2.13.1, but you have keras 2.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.7.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement opencv-python-headless==4.5.2.52 (from versions: 3.4.10.37, 3.4.11.39, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.15.55, 3.4.16.59, 3.4.17.61, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.40, 4.4.0.42, 4.4.0.44, 4.4.0.46, 4.5.1.48, 4.5.3.56, 4.5.4.58, 4.5.4.60, 4.5.5.62, 4.5.5.64, 4.6.0.66, 4.7.0.68, 4.7.0.72, 4.8.0.74, 4.8.0.76)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for opencv-python-headless==4.5.2.52\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [{'name':'carro', 'id': 1}, {'name': 'motos', 'id': 2}]\n",
        "with open(\"/content/label_map.pbtxt\", \"w\") as f:\n",
        "  for label in labels:\n",
        "    f.write('item { \\n')\n",
        "    f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "    f.write('\\tid:{}\\n'.format(label['id']))\n",
        "    f.write('}\\n')"
      ],
      "metadata": {
        "id": "6HKVO-kWJBue"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "%cd /content/models/\n",
        "#!git checkout 58d19c67e1d30d905dd5c6e5092348658fed80af\n",
        "!apt-get update && apt-get install -y -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "!pip install -q pycocotools\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "metadata": {
        "id": "RdlVC0FeJT-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz \\\n",
        "-O /content/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz"
      ],
      "metadata": {
        "id": "LBwrAucyK_4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c140c30a-b972-4c46-8d87-32e752a03cec"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-17 22:16:21--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 64.233.182.207, 64.233.183.207, 173.194.193.207, ...\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|64.233.182.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20515344 (20M) [application/x-tar]\n",
            "Saving to: ‘/content/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n",
            "\n",
            "/content/ssd_mobile 100%[===================>]  19.56M  99.1MB/s    in 0.2s    \n",
            "\n",
            "2023-09-17 22:16:21 (99.1 MB/s) - ‘/content/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar zxvf /content/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
        "output_path = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "output_path = os.path.join(os.getcwd(), output_path)\n",
        "output_path"
      ],
      "metadata": {
        "id": "V_8EqB3iLrI4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "e5c16753-0a74-4ef2-c80b-f8fc02bf2626"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/models/research/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_training = '/content/ssd_mobilenet'\n",
        "os.mkdir(path_training)"
      ],
      "metadata": {
        "id": "OGCj3U7fM75e"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_config = '{}/pipeline.config'.format(output_path)\n",
        "target_config = '{}/pipeline.config'.format(path_training)\n",
        "shutil.copyfile(source_config, target_config)"
      ],
      "metadata": {
        "id": "x-XrA9EING-1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "76c6b369-3d51-4792-c34f-1f0b27c89902"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/ssd_mobilenet/pipeline.config'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ],
      "metadata": {
        "id": "zqFan_9SOG3k"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = config_util.get_configs_from_pipeline_file(target_config)\n",
        "config"
      ],
      "metadata": {
        "id": "dvzHO2gFOdAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3443a68d-fa12-4e28-f784-a077f0efef17"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model': ssd {\n",
              "   num_classes: 90\n",
              "   image_resizer {\n",
              "     fixed_shape_resizer {\n",
              "       height: 320\n",
              "       width: 320\n",
              "     }\n",
              "   }\n",
              "   feature_extractor {\n",
              "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
              "     depth_multiplier: 1.0\n",
              "     min_depth: 16\n",
              "     conv_hyperparams {\n",
              "       regularizer {\n",
              "         l2_regularizer {\n",
              "           weight: 3.9999998989515007e-05\n",
              "         }\n",
              "       }\n",
              "       initializer {\n",
              "         random_normal_initializer {\n",
              "           mean: 0.0\n",
              "           stddev: 0.009999999776482582\n",
              "         }\n",
              "       }\n",
              "       activation: RELU_6\n",
              "       batch_norm {\n",
              "         decay: 0.996999979019165\n",
              "         scale: true\n",
              "         epsilon: 0.0010000000474974513\n",
              "       }\n",
              "     }\n",
              "     use_depthwise: true\n",
              "     override_base_feature_extractor_hyperparams: true\n",
              "     fpn {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       additional_layer_depth: 128\n",
              "     }\n",
              "   }\n",
              "   box_coder {\n",
              "     faster_rcnn_box_coder {\n",
              "       y_scale: 10.0\n",
              "       x_scale: 10.0\n",
              "       height_scale: 5.0\n",
              "       width_scale: 5.0\n",
              "     }\n",
              "   }\n",
              "   matcher {\n",
              "     argmax_matcher {\n",
              "       matched_threshold: 0.5\n",
              "       unmatched_threshold: 0.5\n",
              "       ignore_thresholds: false\n",
              "       negatives_lower_than_unmatched: true\n",
              "       force_match_for_each_row: true\n",
              "       use_matmul_gather: true\n",
              "     }\n",
              "   }\n",
              "   similarity_calculator {\n",
              "     iou_similarity {\n",
              "     }\n",
              "   }\n",
              "   box_predictor {\n",
              "     weight_shared_convolutional_box_predictor {\n",
              "       conv_hyperparams {\n",
              "         regularizer {\n",
              "           l2_regularizer {\n",
              "             weight: 3.9999998989515007e-05\n",
              "           }\n",
              "         }\n",
              "         initializer {\n",
              "           random_normal_initializer {\n",
              "             mean: 0.0\n",
              "             stddev: 0.009999999776482582\n",
              "           }\n",
              "         }\n",
              "         activation: RELU_6\n",
              "         batch_norm {\n",
              "           decay: 0.996999979019165\n",
              "           scale: true\n",
              "           epsilon: 0.0010000000474974513\n",
              "         }\n",
              "       }\n",
              "       depth: 128\n",
              "       num_layers_before_predictor: 4\n",
              "       kernel_size: 3\n",
              "       class_prediction_bias_init: -4.599999904632568\n",
              "       share_prediction_tower: true\n",
              "       use_depthwise: true\n",
              "     }\n",
              "   }\n",
              "   anchor_generator {\n",
              "     multiscale_anchor_generator {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       anchor_scale: 4.0\n",
              "       aspect_ratios: 1.0\n",
              "       aspect_ratios: 2.0\n",
              "       aspect_ratios: 0.5\n",
              "       scales_per_octave: 2\n",
              "     }\n",
              "   }\n",
              "   post_processing {\n",
              "     batch_non_max_suppression {\n",
              "       score_threshold: 9.99999993922529e-09\n",
              "       iou_threshold: 0.6000000238418579\n",
              "       max_detections_per_class: 100\n",
              "       max_total_detections: 100\n",
              "       use_static_shapes: false\n",
              "     }\n",
              "     score_converter: SIGMOID\n",
              "   }\n",
              "   normalize_loss_by_num_matches: true\n",
              "   loss {\n",
              "     localization_loss {\n",
              "       weighted_smooth_l1 {\n",
              "       }\n",
              "     }\n",
              "     classification_loss {\n",
              "       weighted_sigmoid_focal {\n",
              "         gamma: 2.0\n",
              "         alpha: 0.25\n",
              "       }\n",
              "     }\n",
              "     classification_weight: 1.0\n",
              "     localization_weight: 1.0\n",
              "   }\n",
              "   encode_background_as_zeros: true\n",
              "   normalize_loc_loss_by_codesize: true\n",
              "   inplace_batchnorm_update: true\n",
              "   freeze_batchnorm: false\n",
              " },\n",
              " 'train_config': batch_size: 128\n",
              " data_augmentation_options {\n",
              "   random_horizontal_flip {\n",
              "   }\n",
              " }\n",
              " data_augmentation_options {\n",
              "   random_crop_image {\n",
              "     min_object_covered: 0.0\n",
              "     min_aspect_ratio: 0.75\n",
              "     max_aspect_ratio: 3.0\n",
              "     min_area: 0.75\n",
              "     max_area: 1.0\n",
              "     overlap_thresh: 0.0\n",
              "   }\n",
              " }\n",
              " sync_replicas: true\n",
              " optimizer {\n",
              "   momentum_optimizer {\n",
              "     learning_rate {\n",
              "       cosine_decay_learning_rate {\n",
              "         learning_rate_base: 0.07999999821186066\n",
              "         total_steps: 50000\n",
              "         warmup_learning_rate: 0.026666000485420227\n",
              "         warmup_steps: 1000\n",
              "       }\n",
              "     }\n",
              "     momentum_optimizer_value: 0.8999999761581421\n",
              "   }\n",
              "   use_moving_average: false\n",
              " }\n",
              " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
              " num_steps: 50000\n",
              " startup_delay_steps: 0.0\n",
              " replicas_to_aggregate: 8\n",
              " max_number_of_boxes: 100\n",
              " unpad_groundtruth_tensors: false\n",
              " fine_tune_checkpoint_type: \"classification\"\n",
              " fine_tune_checkpoint_version: V2,\n",
              " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " },\n",
              " 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
              " use_moving_averages: false,\n",
              " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }\n",
              " ],\n",
              " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(target_config, 'r') as f:\n",
        "  proto_str = f.read()\n",
        "  text_format.Merge(proto_str, pipeline_config)\n",
        "pipeline_config"
      ],
      "metadata": {
        "id": "7eBD2YPwOwuT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01911ba8-23ac-43fe-9b38-8fd5b8e67822"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model {\n",
              "  ssd {\n",
              "    num_classes: 90\n",
              "    image_resizer {\n",
              "      fixed_shape_resizer {\n",
              "        height: 320\n",
              "        width: 320\n",
              "      }\n",
              "    }\n",
              "    feature_extractor {\n",
              "      type: \"ssd_mobilenet_v2_fpn_keras\"\n",
              "      depth_multiplier: 1.0\n",
              "      min_depth: 16\n",
              "      conv_hyperparams {\n",
              "        regularizer {\n",
              "          l2_regularizer {\n",
              "            weight: 3.9999998989515007e-05\n",
              "          }\n",
              "        }\n",
              "        initializer {\n",
              "          random_normal_initializer {\n",
              "            mean: 0.0\n",
              "            stddev: 0.009999999776482582\n",
              "          }\n",
              "        }\n",
              "        activation: RELU_6\n",
              "        batch_norm {\n",
              "          decay: 0.996999979019165\n",
              "          scale: true\n",
              "          epsilon: 0.0010000000474974513\n",
              "        }\n",
              "      }\n",
              "      use_depthwise: true\n",
              "      override_base_feature_extractor_hyperparams: true\n",
              "      fpn {\n",
              "        min_level: 3\n",
              "        max_level: 7\n",
              "        additional_layer_depth: 128\n",
              "      }\n",
              "    }\n",
              "    box_coder {\n",
              "      faster_rcnn_box_coder {\n",
              "        y_scale: 10.0\n",
              "        x_scale: 10.0\n",
              "        height_scale: 5.0\n",
              "        width_scale: 5.0\n",
              "      }\n",
              "    }\n",
              "    matcher {\n",
              "      argmax_matcher {\n",
              "        matched_threshold: 0.5\n",
              "        unmatched_threshold: 0.5\n",
              "        ignore_thresholds: false\n",
              "        negatives_lower_than_unmatched: true\n",
              "        force_match_for_each_row: true\n",
              "        use_matmul_gather: true\n",
              "      }\n",
              "    }\n",
              "    similarity_calculator {\n",
              "      iou_similarity {\n",
              "      }\n",
              "    }\n",
              "    box_predictor {\n",
              "      weight_shared_convolutional_box_predictor {\n",
              "        conv_hyperparams {\n",
              "          regularizer {\n",
              "            l2_regularizer {\n",
              "              weight: 3.9999998989515007e-05\n",
              "            }\n",
              "          }\n",
              "          initializer {\n",
              "            random_normal_initializer {\n",
              "              mean: 0.0\n",
              "              stddev: 0.009999999776482582\n",
              "            }\n",
              "          }\n",
              "          activation: RELU_6\n",
              "          batch_norm {\n",
              "            decay: 0.996999979019165\n",
              "            scale: true\n",
              "            epsilon: 0.0010000000474974513\n",
              "          }\n",
              "        }\n",
              "        depth: 128\n",
              "        num_layers_before_predictor: 4\n",
              "        kernel_size: 3\n",
              "        class_prediction_bias_init: -4.599999904632568\n",
              "        share_prediction_tower: true\n",
              "        use_depthwise: true\n",
              "      }\n",
              "    }\n",
              "    anchor_generator {\n",
              "      multiscale_anchor_generator {\n",
              "        min_level: 3\n",
              "        max_level: 7\n",
              "        anchor_scale: 4.0\n",
              "        aspect_ratios: 1.0\n",
              "        aspect_ratios: 2.0\n",
              "        aspect_ratios: 0.5\n",
              "        scales_per_octave: 2\n",
              "      }\n",
              "    }\n",
              "    post_processing {\n",
              "      batch_non_max_suppression {\n",
              "        score_threshold: 9.99999993922529e-09\n",
              "        iou_threshold: 0.6000000238418579\n",
              "        max_detections_per_class: 100\n",
              "        max_total_detections: 100\n",
              "        use_static_shapes: false\n",
              "      }\n",
              "      score_converter: SIGMOID\n",
              "    }\n",
              "    normalize_loss_by_num_matches: true\n",
              "    loss {\n",
              "      localization_loss {\n",
              "        weighted_smooth_l1 {\n",
              "        }\n",
              "      }\n",
              "      classification_loss {\n",
              "        weighted_sigmoid_focal {\n",
              "          gamma: 2.0\n",
              "          alpha: 0.25\n",
              "        }\n",
              "      }\n",
              "      classification_weight: 1.0\n",
              "      localization_weight: 1.0\n",
              "    }\n",
              "    encode_background_as_zeros: true\n",
              "    normalize_loc_loss_by_codesize: true\n",
              "    inplace_batchnorm_update: true\n",
              "    freeze_batchnorm: false\n",
              "  }\n",
              "}\n",
              "train_config {\n",
              "  batch_size: 128\n",
              "  data_augmentation_options {\n",
              "    random_horizontal_flip {\n",
              "    }\n",
              "  }\n",
              "  data_augmentation_options {\n",
              "    random_crop_image {\n",
              "      min_object_covered: 0.0\n",
              "      min_aspect_ratio: 0.75\n",
              "      max_aspect_ratio: 3.0\n",
              "      min_area: 0.75\n",
              "      max_area: 1.0\n",
              "      overlap_thresh: 0.0\n",
              "    }\n",
              "  }\n",
              "  sync_replicas: true\n",
              "  optimizer {\n",
              "    momentum_optimizer {\n",
              "      learning_rate {\n",
              "        cosine_decay_learning_rate {\n",
              "          learning_rate_base: 0.07999999821186066\n",
              "          total_steps: 50000\n",
              "          warmup_learning_rate: 0.026666000485420227\n",
              "          warmup_steps: 1000\n",
              "        }\n",
              "      }\n",
              "      momentum_optimizer_value: 0.8999999761581421\n",
              "    }\n",
              "    use_moving_average: false\n",
              "  }\n",
              "  fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
              "  num_steps: 50000\n",
              "  startup_delay_steps: 0.0\n",
              "  replicas_to_aggregate: 8\n",
              "  max_number_of_boxes: 100\n",
              "  unpad_groundtruth_tensors: false\n",
              "  fine_tune_checkpoint_type: \"classification\"\n",
              "  fine_tune_checkpoint_version: V2\n",
              "}\n",
              "train_input_reader {\n",
              "  label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              "  tf_record_input_reader {\n",
              "    input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              "  }\n",
              "}\n",
              "eval_config {\n",
              "  metrics_set: \"coco_detection_metrics\"\n",
              "  use_moving_averages: false\n",
              "}\n",
              "eval_input_reader {\n",
              "  label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              "  shuffle: false\n",
              "  num_epochs: 1\n",
              "  tf_record_input_reader {\n",
              "    input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_map_pbtext_fname = '/content/label_map.pbtxt'\n",
        "train_record_fname = '/content/train.record'\n",
        "test_record_fname = '/content/test.record'"
      ],
      "metadata": {
        "id": "n7IEBIqwQij8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_config.model.ssd.num_classes = 2\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "pipeline_config.train_config.fine_tune_checkpoint = '{}/checkpoint/ckpt-0'.format(output_path)\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = 'detection'\n",
        "pipeline_config.train_input_reader.label_map_path = label_map_pbtext_fname\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[0] = train_record_fname\n",
        "pipeline_config.eval_input_reader[0].label_map_path = label_map_pbtext_fname\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[0] = test_record_fname\n",
        "pipeline_config"
      ],
      "metadata": {
        "id": "GdG7l3wGPy0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfb5e203-3f33-4a70-af59-e919f4727e98"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model {\n",
              "  ssd {\n",
              "    num_classes: 2\n",
              "    image_resizer {\n",
              "      fixed_shape_resizer {\n",
              "        height: 320\n",
              "        width: 320\n",
              "      }\n",
              "    }\n",
              "    feature_extractor {\n",
              "      type: \"ssd_mobilenet_v2_fpn_keras\"\n",
              "      depth_multiplier: 1.0\n",
              "      min_depth: 16\n",
              "      conv_hyperparams {\n",
              "        regularizer {\n",
              "          l2_regularizer {\n",
              "            weight: 3.9999998989515007e-05\n",
              "          }\n",
              "        }\n",
              "        initializer {\n",
              "          random_normal_initializer {\n",
              "            mean: 0.0\n",
              "            stddev: 0.009999999776482582\n",
              "          }\n",
              "        }\n",
              "        activation: RELU_6\n",
              "        batch_norm {\n",
              "          decay: 0.996999979019165\n",
              "          scale: true\n",
              "          epsilon: 0.0010000000474974513\n",
              "        }\n",
              "      }\n",
              "      use_depthwise: true\n",
              "      override_base_feature_extractor_hyperparams: true\n",
              "      fpn {\n",
              "        min_level: 3\n",
              "        max_level: 7\n",
              "        additional_layer_depth: 128\n",
              "      }\n",
              "    }\n",
              "    box_coder {\n",
              "      faster_rcnn_box_coder {\n",
              "        y_scale: 10.0\n",
              "        x_scale: 10.0\n",
              "        height_scale: 5.0\n",
              "        width_scale: 5.0\n",
              "      }\n",
              "    }\n",
              "    matcher {\n",
              "      argmax_matcher {\n",
              "        matched_threshold: 0.5\n",
              "        unmatched_threshold: 0.5\n",
              "        ignore_thresholds: false\n",
              "        negatives_lower_than_unmatched: true\n",
              "        force_match_for_each_row: true\n",
              "        use_matmul_gather: true\n",
              "      }\n",
              "    }\n",
              "    similarity_calculator {\n",
              "      iou_similarity {\n",
              "      }\n",
              "    }\n",
              "    box_predictor {\n",
              "      weight_shared_convolutional_box_predictor {\n",
              "        conv_hyperparams {\n",
              "          regularizer {\n",
              "            l2_regularizer {\n",
              "              weight: 3.9999998989515007e-05\n",
              "            }\n",
              "          }\n",
              "          initializer {\n",
              "            random_normal_initializer {\n",
              "              mean: 0.0\n",
              "              stddev: 0.009999999776482582\n",
              "            }\n",
              "          }\n",
              "          activation: RELU_6\n",
              "          batch_norm {\n",
              "            decay: 0.996999979019165\n",
              "            scale: true\n",
              "            epsilon: 0.0010000000474974513\n",
              "          }\n",
              "        }\n",
              "        depth: 128\n",
              "        num_layers_before_predictor: 4\n",
              "        kernel_size: 3\n",
              "        class_prediction_bias_init: -4.599999904632568\n",
              "        share_prediction_tower: true\n",
              "        use_depthwise: true\n",
              "      }\n",
              "    }\n",
              "    anchor_generator {\n",
              "      multiscale_anchor_generator {\n",
              "        min_level: 3\n",
              "        max_level: 7\n",
              "        anchor_scale: 4.0\n",
              "        aspect_ratios: 1.0\n",
              "        aspect_ratios: 2.0\n",
              "        aspect_ratios: 0.5\n",
              "        scales_per_octave: 2\n",
              "      }\n",
              "    }\n",
              "    post_processing {\n",
              "      batch_non_max_suppression {\n",
              "        score_threshold: 9.99999993922529e-09\n",
              "        iou_threshold: 0.6000000238418579\n",
              "        max_detections_per_class: 100\n",
              "        max_total_detections: 100\n",
              "        use_static_shapes: false\n",
              "      }\n",
              "      score_converter: SIGMOID\n",
              "    }\n",
              "    normalize_loss_by_num_matches: true\n",
              "    loss {\n",
              "      localization_loss {\n",
              "        weighted_smooth_l1 {\n",
              "        }\n",
              "      }\n",
              "      classification_loss {\n",
              "        weighted_sigmoid_focal {\n",
              "          gamma: 2.0\n",
              "          alpha: 0.25\n",
              "        }\n",
              "      }\n",
              "      classification_weight: 1.0\n",
              "      localization_weight: 1.0\n",
              "    }\n",
              "    encode_background_as_zeros: true\n",
              "    normalize_loc_loss_by_codesize: true\n",
              "    inplace_batchnorm_update: true\n",
              "    freeze_batchnorm: false\n",
              "  }\n",
              "}\n",
              "train_config {\n",
              "  batch_size: 4\n",
              "  data_augmentation_options {\n",
              "    random_horizontal_flip {\n",
              "    }\n",
              "  }\n",
              "  data_augmentation_options {\n",
              "    random_crop_image {\n",
              "      min_object_covered: 0.0\n",
              "      min_aspect_ratio: 0.75\n",
              "      max_aspect_ratio: 3.0\n",
              "      min_area: 0.75\n",
              "      max_area: 1.0\n",
              "      overlap_thresh: 0.0\n",
              "    }\n",
              "  }\n",
              "  sync_replicas: true\n",
              "  optimizer {\n",
              "    momentum_optimizer {\n",
              "      learning_rate {\n",
              "        cosine_decay_learning_rate {\n",
              "          learning_rate_base: 0.07999999821186066\n",
              "          total_steps: 50000\n",
              "          warmup_learning_rate: 0.026666000485420227\n",
              "          warmup_steps: 1000\n",
              "        }\n",
              "      }\n",
              "      momentum_optimizer_value: 0.8999999761581421\n",
              "    }\n",
              "    use_moving_average: false\n",
              "  }\n",
              "  fine_tune_checkpoint: \"/content/models/research/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0\"\n",
              "  num_steps: 50000\n",
              "  startup_delay_steps: 0.0\n",
              "  replicas_to_aggregate: 8\n",
              "  max_number_of_boxes: 100\n",
              "  unpad_groundtruth_tensors: false\n",
              "  fine_tune_checkpoint_type: \"detection\"\n",
              "  fine_tune_checkpoint_version: V2\n",
              "}\n",
              "train_input_reader {\n",
              "  label_map_path: \"/content/label_map.pbtxt\"\n",
              "  tf_record_input_reader {\n",
              "    input_path: \"/content/train.record\"\n",
              "  }\n",
              "}\n",
              "eval_config {\n",
              "  metrics_set: \"coco_detection_metrics\"\n",
              "  use_moving_averages: false\n",
              "}\n",
              "eval_input_reader {\n",
              "  label_map_path: \"/content/label_map.pbtxt\"\n",
              "  shuffle: false\n",
              "  num_epochs: 1\n",
              "  tf_record_input_reader {\n",
              "    input_path: \"/content/test.record\"\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#write configuration pipeline in file\n",
        "config_text = text_format.MessageToString(pipeline_config)\n",
        "with tf.io.gfile.GFile(target_config, 'wb') as f:\n",
        "  f.write(config_text)"
      ],
      "metadata": {
        "id": "6itoHUicUuvx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Keras-Preprocessing\n",
        "!pip install 'keras>=2.9.0'\n",
        "!pip install avro-python3\n",
        "!pip install tf_slim == 1.1.0\n",
        "!pip install lvis\n",
        "!pip install opencv-python-headless == 4.5.2.52\n",
        "!pip install tensorflow == 2.7.0\n",
        "!pip install tf-models-official == 2.7.0\n",
        "!pip install tensorflow_io == 0.23.1\n",
        "!pip install keras == 2.7.0\n",
        "!pip install tensorboard == 2.7.0\n",
        "!pip install tensorflow-text == 2.7.0\n",
        "!pip install tensorflow-gcs-config == 2.7.0\n"
      ],
      "metadata": {
        "id": "-JWN8bG1q0FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_steps = 5000\n",
        "model_dir = '/content/ssd_mobilenet'\n",
        "\n",
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "--pipeline_config_path={target_config} \\\n",
        "--model_dir={model_dir} \\\n",
        "--num_train_steps={num_steps}"
      ],
      "metadata": {
        "id": "bCrCaemNn-DZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}